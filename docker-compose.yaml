services:
  default:
    build: .
    image: llama-index-env-default
    volumes:
      - .:/workspace
      - type: bind
        source: ${STORAGE}/.cache
        target: /root/.cache
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    stdin_open: true
    tty: true
